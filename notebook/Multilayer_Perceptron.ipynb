{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25b0ed9",
   "metadata": {},
   "source": [
    "# **Handwritten Digit Recognition with MLP**\n",
    "\n",
    "**About This Project:**\n",
    "\n",
    "This project is a complete implementation of a **Multilayer Perceptron (MLP)** built entirely **from scratch**, without using high-level machine learning libraries such as TensorFlow or PyTorch.  \n",
    "\n",
    "The purpose of this project is to create a neural network capable of **recognizing handwritten digits** (0â€“9) and to gain a **deep practical understanding of how MLPs work**, including forward propagation, activation functions, backpropagation, and gradient descent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03e3ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f38c5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X.values\n",
    "y = y.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d73852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "660c212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ((X / 255.) - .5) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0902ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5,\n",
    "\n",
    "                        sharex=True, sharey=True)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "\n",
    "     img = X[y == i][0].reshape(28, 28)\n",
    "\n",
    "     ax[i].imshow(img, cmap='Greys')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9b92e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d36df2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=10000, random_state=42, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=5000,random_state=123, stratify=y_temp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05c7b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "\n",
    "def int_to_onehot(y, num_labels):\n",
    "    ary = np.zeros((y.shape[0], num_labels), dtype=float)\n",
    "    for i, val in enumerate(y):\n",
    "        ary[i, val] = 1.0\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5e80da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multilayer_Perceptron:\n",
    "    def __init__(self, num_features, num_hidden, num_classes, random_state=42):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        rng = np.random.RandomState(random_state) # Create a random number generator with a fixed seed for reproducibility\n",
    "\n",
    "        # Initialize hidden layer weights\n",
    "        self.weight_h = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_hidden, num_features))\n",
    "        # Initialized from a normal distribution (mean=0.0, std=0.1)\n",
    "        \n",
    "        self.bias_h = np.zeros(num_hidden)\n",
    "        # Bias vector for hidden layer neurons, initialized to 0\n",
    "\n",
    "        # Initialize output layer weights\n",
    "\n",
    "        self.weight_out = rng.normal(\n",
    "            loc=0.0, scale=0.1, size=(num_classes, num_hidden))\n",
    "        # weight_out shape: (num_classes, num_hidden)\n",
    "        # Each output neuron has a weight for each hidden neuron\n",
    "        \n",
    "        self.bias_out = np.zeros(num_classes)\n",
    "        # Bias vector for output layer neurons, initialized to 0\n",
    "        # Shape: (num_classes,)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Hidden layer\n",
    "\n",
    "        y_hat = np.dot(x, self.weight_h.T) + self.bias_h\n",
    "        a_h = sigmoid(y_hat)\n",
    "\n",
    "         # Output layer\n",
    "\n",
    "        y_out = np.dot(a_h, self.weight_out.T) + self.bias_out\n",
    "        a_out = sigmoid(y_out)\n",
    "\n",
    "        return a_h, a_out\n",
    "    \n",
    "    def backward(self, x, a_h, a_out,y):\n",
    "\n",
    "        #########################\n",
    "        ### Output layer weights\n",
    "        #########################\n",
    "\n",
    "        y_onehot = int_to_onehot(y)\n",
    "\n",
    "        #Part 1: dLoss/dOutWeights\n",
    "\n",
    "        # input/output dim: [n_examples, n_classes]\n",
    "        d_loss_d_a_out = 2. *(a_out - y_onehot) / y.shape[0]\n",
    "\n",
    "        d_a_out_d_z_out = a_out * (1. - a_out)\n",
    "\n",
    "        delta_out = d_loss_d_a_out*d_a_out_d_z_out\n",
    "\n",
    "        d_z_out__dw_out = a_h\n",
    "\n",
    "        d_loss__dw_out = np.dot(delta_out.T, d_z_out__dw_out)\n",
    "\n",
    "        d_loss__db_out = np.sum(delta_out, axis=0)\n",
    "\n",
    "        # Part 2: dLoss/dHiddenWeights\n",
    "\n",
    "        # [n_classes, n_hidden]\n",
    "\n",
    "        d_z_out__a_h = self.weight_out\n",
    "\n",
    "        d_loss__a_h = np.dot(delta_out, d_z_out__a_h)\n",
    "\n",
    "        d_a_h__d_z_h = a_h * (1 - a_h)\n",
    "\n",
    "        d_z_h__d_w_h = x\n",
    "\n",
    "        d_loss__d_w_h = np.dot((d_loss__a_h * d_a_h__d_z_h).T, d_z_h__d_w_h)\n",
    "\n",
    "        d_loss__d_b_h = np.sum((d_loss__a_h * d_a_h__d_z_h), axis=0)\n",
    "\n",
    "        return (d_loss__dw_out, d_loss__db_out,\n",
    "        d_loss__d_w_h, d_loss__d_b_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac9e4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multilayer_Perceptron(num_features=28*28,\n",
    "                              num_hidden=50,\n",
    "                              num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb910dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "minibatch_sizes = 100\n",
    "\n",
    "def minibatch_gen(X, y, minibatch_size):\n",
    "\n",
    "    indices = np.arange(X.shape[0])\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start_idx in range(0, indices.shape[0] - minibatch_size + 1, minibatch_size):\n",
    "        batch_idx = indices[start_idx:start_idx + minibatch_size]\n",
    "\n",
    "        yield X[batch_idx], y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26b7307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "\n",
    "    batch_gen = minibatch_gen(X, y, minibatch_sizes)\n",
    "    for X_train_mini, y_train_mini in batch_gen:\n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "print(X_train_mini.shape)\n",
    "print(y_train_mini.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3119096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(targets, probas, num_labels=10):\n",
    "    onehot_targets = int_to_onehot(targets, num_labels=num_labels)\n",
    "    return np.mean((onehot_targets - probas)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb938e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(targets, predicted_labels):\n",
    "    return np.mean(predicted_labels == targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b45a830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, probas = model.forward(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33b5e4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation MSE: 0.3\n"
     ]
    }
   ],
   "source": [
    "mse = mse_loss(y_valid, probas)\n",
    "print(f'Initial validation MSE: {mse:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fed8a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial validation accuracy: 9.8%\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(probas, axis=1)\n",
    "acc = accuracy1(y_valid, predicted_labels)\n",
    "print(f'Initial validation accuracy: {acc*100:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e677b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_valid, y_valid,\n",
    "          num_epochs=50, minibatch_size=100, learning_rate=0.1,\n",
    "          verbose=True):\n",
    "     train_mse_history = []\n",
    "     train_acc_history = []\n",
    "     valid_acc_history = []\n",
    "\n",
    "     for epoch in range(num_epochs):\n",
    "        # Minibatch loop\n",
    "        for X_batch, y_batch in minibatch_gen(X_train, y_train, minibatch_size):\n",
    "            # Forward pass\n",
    "            a_h, probas = model.forward(X_batch)\n",
    "\n",
    "            # Backward pass\n",
    "            d_w_out, d_b_out, d_w_h, d_b_h = model.backward(X_batch, a_h, probas, y_batch)\n",
    "\n",
    "            # Update weights\n",
    "            model.weight_h   -= learning_rate * d_w_h\n",
    "            model.bias_h     -= learning_rate * d_b_h\n",
    "            model.weight_out -= learning_rate * d_w_out\n",
    "            model.bias_out   -= learning_rate * d_b_out\n",
    "\n",
    "        # ---- Metrics evaluation at end of epoch ----\n",
    "        # Training metrics\n",
    "        _, train_probas = model.forward(X_train)\n",
    "        y_train_pred = np.argmax(train_probas, axis=1)\n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        train_mse = mean_squared_error(int_to_onehot(y_train, num_labels=model.num_classes),\n",
    "                                       train_probas)\n",
    "\n",
    "        # Validation metrics\n",
    "        _, val_probas = model.forward(X_valid)\n",
    "        y_val_pred = np.argmax(val_probas, axis=1)\n",
    "        val_acc = accuracy_score(y_valid, y_val_pred)\n",
    "\n",
    "        # Store metrics\n",
    "        train_mse_history.append(train_mse)\n",
    "        train_acc_history.append(train_acc*100)\n",
    "        valid_acc_history.append(val_acc*100)\n",
    "\n",
    "        # Print epoch summary\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "                  f\"Train MSE: {train_mse:.4f} | \"\n",
    "                  f\"Train Acc: {train_acc*100:.2f}% | \"\n",
    "                  f\"Valid Acc: {val_acc*100:.2f}%\")\n",
    "     return train_mse_history, train_acc_history, valid_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1809756",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int_to_onehot() missing 1 required positional argument: 'num_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m epoch_loss, epoch_train_acc, epoch_valid_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[58], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, X_train, y_train, X_valid, y_valid, num_epochs, minibatch_size, learning_rate, verbose)\u001b[0m\n\u001b[0;32m     12\u001b[0m a_h, probas \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(X_batch)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m d_w_out, d_b_out, d_w_h, d_b_h \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mweight_h   \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m d_w_h\n",
      "Cell \u001b[1;32mIn[46], line 49\u001b[0m, in \u001b[0;36mMultilayer_Perceptron.backward\u001b[1;34m(self, x, a_h, a_out, y)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, a_h, a_out,y):\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m#########################\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m### Output layer weights\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m#########################\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     y_onehot \u001b[38;5;241m=\u001b[39m \u001b[43mint_to_onehot\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m#Part 1: dLoss/dOutWeights\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# input/output dim: [n_examples, n_classes]\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     d_loss_d_a_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m*\u001b[39m(a_out \u001b[38;5;241m-\u001b[39m y_onehot) \u001b[38;5;241m/\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: int_to_onehot() missing 1 required positional argument: 'num_labels'"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "epoch_loss, epoch_train_acc, epoch_valid_acc = train(\n",
    "    model, X_train, y_train, X_valid, y_valid,\n",
    "    num_epochs=50, learning_rate=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
